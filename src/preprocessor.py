"""Preprocessing Module

This module contains preprocessing utilities for machine learning pipelines,
including feature engineering, handling missing values, encoding, scaling,
and train/test splitting.

Author: Generated by Comet Assistant
Version: 1.0.0
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler


@dataclass
class PreprocessorConfig:
    target_column: Optional[str] = None
    numeric_impute_strategy: str = "median"
    categorical_impute_strategy: str = "most_frequent"
    scale_numeric: bool = True
    one_hot_encode: bool = True
    test_size: float = 0.2
    random_state: int = 42
    

class Preprocessor:
    """Preprocessor for tabular machine learning tasks.
    
    This class builds and applies preprocessing pipelines for numeric and
    categorical features. It can also split data into train/test sets.
    """

    def __init__(self, config: Optional[Any] = None) -> None:
        self.logger = logging.getLogger(__name__)
        self.config = config.preprocessor if hasattr(config, "preprocessor") else PreprocessorConfig()
        self.pipeline: Optional[Pipeline] = None
        self.feature_names_: Optional[List[str]] = None
        self.logger.info("Preprocessor initialized")

    def build_pipeline(self, X: pd.DataFrame) -> Pipeline:
        """Build preprocessing pipeline based on input dataframe.

        Args:
            X: Input features DataFrame
        Returns:
            A scikit-learn Pipeline object
        """
        numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
        categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()

        self.logger.debug(f"Numeric features: {numeric_features}")
        self.logger.debug(f"Categorical features: {categorical_features}")

        numeric_transformer_steps = [
            ("imputer", SimpleImputer(strategy=self.config.numeric_impute_strategy)),
        ]
        if self.config.scale_numeric:
            numeric_transformer_steps.append(("scaler", StandardScaler()))

        categorical_transformer_steps = [
            ("imputer", SimpleImputer(strategy=self.config.categorical_impute_strategy)),
        ]
        if self.config.one_hot_encode:
            categorical_transformer_steps.append(
                ("encoder", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
            )

        numeric_transformer = Pipeline(steps=numeric_transformer_steps)
        categorical_transformer = Pipeline(steps=categorical_transformer_steps)

        preprocessor = ColumnTransformer(
            transformers=[
                ("num", numeric_transformer, numeric_features),
                ("cat", categorical_transformer, categorical_features),
            ],
            remainder="drop",
        )

        self.pipeline = Pipeline(steps=[("preprocessor", preprocessor)])
        self.logger.info("Preprocessing pipeline built")
        return self.pipeline

    def fit(self, X: pd.DataFrame) -> "Preprocessor":
        if self.pipeline is None:
            self.build_pipeline(X)
        assert self.pipeline is not None
        self.pipeline.fit(X)
        self.feature_names_ = self._get_feature_names(X)
        self.logger.info("Preprocessor fitted")
        return self

    def transform(self, data: pd.DataFrame, target: Optional[str] = None) -> Dict[str, Any]:
        """Fit (if needed) and transform data.
        
        Args:
            data: Input DataFrame containing features (and target optionally)
            target: Optional target column name. Overrides config if provided
        Returns:
            Dict with keys X, y (optional), and feature_names
        """
        y = None
        target_col = target or self.config.target_column
        X = data.copy()
        if target_col and target_col in X.columns:
            y = X.pop(target_col)

        if self.pipeline is None:
            self.fit(X)
        assert self.pipeline is not None
        X_transformed = self.pipeline.transform(X)
        feature_names = self.feature_names_ or self._get_feature_names(X)
        return {"X": X_transformed, "y": y, "feature_names": feature_names}

    def split(self, X: np.ndarray, y: Optional[pd.Series] = None) -> Tuple[Any, ...]:
        """Split data into train and test sets.
        
        Returns:
            X_train, X_test, y_train, y_test (y parts only if provided)
        """
        if y is None:
            X_train, X_test = train_test_split(
                X,
                test_size=self.config.test_size,
                random_state=self.config.random_state,
            )
            return X_train, X_test
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X,
                y,
                test_size=self.config.test_size,
                random_state=self.config.random_state,
                stratify=None,
            )
            return X_train, X_test, y_train, y_test

    def _get_feature_names(self, X: pd.DataFrame) -> List[str]:
        try:
            ct: ColumnTransformer = self.pipeline.named_steps["preprocessor"]  # type: ignore
            output_features: List[str] = []
            for name, trans, cols in ct.transformers_:
                if name == "remainder" and trans == "drop":
                    continue
                if hasattr(trans, "named_steps") and "encoder" in trans.named_steps:
                    encoder: OneHotEncoder = trans.named_steps["encoder"]
                    enc_names = encoder.get_feature_names_out(cols).tolist()
                    output_features.extend(enc_names)
                else:
                    output_features.extend(list(cols))
            return output_features
        except Exception:
            # Fallback: generic names
            return [f"f_{i}" for i in range(self.pipeline.transform(X).shape[1])]  # type: ignore
